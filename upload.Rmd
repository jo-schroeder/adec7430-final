---
title: ""
output: html_document
---

**Test our models by uploading your own data!**

To download your own data:

- Go to [Google Trends](https://trends.google.com/trends/explore?date=all&geo=US) and make sure you are searching the "United States" for all years of data
- Search any actor you want
- Download from the graph where it says interest over time, download as a csv
- The csv will go to your downloads, upload it to the [upload data here folder](https://github.com/jo-schroeder/adec7430-final/tree/main/data/upload_data_here) of the GitHub repository, make sure you commit the upload
- Wait for the website to rebuild (should take around 5 minutes, there will be a green check on the latest commit message on GitHub)
- Refresh this page and see the analysis with the new data point!

```{r setup, include=FALSE}
# loading packages
library(lubridate)
library(dtwclust)
library(ggthemes)
library(ggplot2)
library(plotly)
library(dplyr)
library(tidyr)
library(tsfeatures)
library(tidymodels)
library(purrr)
library(readr)
library(stringr)
library(caret)
library(randomForest)
library(tibble)

# load in data
data_dir <- "./data/"
actors <- read_csv(paste0(data_dir, "actors_features.csv"))
trends <- read_csv(paste0(data_dir, "trends.csv"))
existing_actors <- colnames(trends)

knitr::opts_chunk$set(
  message = FALSE, warning = FALSE, echo = FALSE
)

# check if any data has been uploaded
uploaded_data_dir <- paste0(data_dir, "upload_data_here/")
new_files <- list.files(uploaded_data_dir)

if (length(new_files) > 0) {
  # Read all files into a list of data frames
  data_list <- lapply(new_files, function(f) {
    read_csv(file.path(uploaded_data_dir, f), skip = 1)
  })

  if (length(data_list) == 1) {
    uploaded_data <- data_list[[1]]
  } else {

    uploaded_data <- Reduce(function(x, y) left_join(x, y, by = "Month"), data_list)
  }
  
  colnames(uploaded_data) <- gsub(": \\(United States\\)", "", colnames(uploaded_data))
  uploaded_data <- head(uploaded_data, 255)

}

```

```{r eval = !(exists("uploaded_data")), results = "asis"}
cat("Nothing has been uploaded.")
```

```{r eval = exists("uploaded_data"), results = "asis"}
trends <- left_join(trends, uploaded_data)
second_colname <- colnames(trends)[2]
last_colname <- tail(colnames(trends), 1)
uploaded_colnames <- colnames(uploaded_data)[-1]
```


```{r eval = exists("uploaded_data"), results = "asis"}
cat("You uploaded: ", uploaded_colnames, ".")

if (uploaded_colnames %in% existing_actors){
  cat("\n", uploaded_colnames, "is already in our dataset")
  uploaded_data <- NULL
} else if (!is.null(uploaded_data) && nrow(uploaded_data) < 255){
  cat("\nYou didn't upload the full time series since 2004")
  uploaded_data <- NULL
} else {
  cat("\nThe data looks good!")
}
```

```{r eval = exists("uploaded_data")}
# interactive trends plot
p <- plot_ly(type = "scatter", mode = "lines")

trends <- trends %>%
  mutate(across(everything(), ~ ifelse(. == "<1", 0, .))) %>%
  mutate(across(c(second_colname:last_colname), ~ as.numeric(.))) %>%
  pivot_longer(cols = c(second_colname:last_colname)) %>%
  mutate(Month = ym(Month),
         uploaded = ifelse(name %in% uploaded_colnames, TRUE, FALSE))

trends %>%
  group_by(name) %>%
  group_split() %>%
  purrr::walk(function(df) {
    p <<- add_trace(p,
                    data = df,
                    x = ~Month,
                    y = ~value,
                    name = unique(df$name),
                    text = ~paste(name, value),
                    hoverinfo = "text",
                    visible = "legendonly")
  })

p %>%
  layout(
    title = "Monthly Search Interest for Selected Actors since 2004",
    xaxis = list(title = "Month", range = c("2004-01-01",
                                            "2025-03-01")),
    yaxis = list(title = "Google Trend Search Interest", range = c(0, 100)),
    legend = list(title = list(text = "Select an Actor"))
  )


# joining 
joined <- trends %>% 
  mutate(name = tolower(name)) %>%
  left_join(actors, by = c("name")) 
```

```{r, eval = exists("uploaded_data"), results='asis'}
wide <- trends %>%
  pivot_wider(names_from = Month, values_from = value) %>%
  tibble::column_to_rownames("name")
ts_matrix <- as.matrix(wide)

clusters <- tsclust(ts_matrix,
                    type = "partitional",
                    k = 5,  # tune this
                    distance = "sbd",
                    centroid = "shape",  # required with SBD
                    control = partitional_control(iter.max = 50),
                    seed = 90210)

cluster_assignments <- clusters@cluster  # cluster labels for each series
distances <- clusters@cldist

# Create a data frame with rownames and cluster assignment
cluster_df <- data.frame(
  name = rownames(ts_matrix),
  cluster = cluster_assignments,
  distance = distances
)

actor_with_cluster <- left_join(trends, cluster_df, by = "name")

uploaded_cluster <- actor_with_cluster %>% filter(name == uploaded_colnames) %>% distinct(cluster) %>% pull(cluster)

cat(uploaded_colnames, "would be in cluster", uploaded_cluster)
```


```{r eval = exists("uploaded_data"), message = FALSE, warning = FALSE, echo = FALSE}
years_seq <- 2004:2024

cluster_df <- cluster_df %>%
  distinct(name, cluster) %>%
  mutate(name = tolower(name))

features <- actors %>% 
  left_join(cluster_df, by = ("name")) %>% 
  select(name, age, gender, american, cluster)

winners <- actors %>%
  mutate(year_winner = str_remove_all(year_winner, "\\[|\\]")) %>%
  separate_rows(year_winner, sep = ",\\s*") %>%             
  mutate(year_winner = as.integer(year_winner)) %>%
  select(name, winner, year_winner)

# Cross join name and years_seq
winners_filled <- winners %>%
  # Create a data frame of all names and years
  distinct(name) %>%
  expand(name, year_winner = years_seq) %>%
  left_join(winners, by = c("name", "year_winner")) %>%
  rename(year = year_winner) %>%
  group_by(name) %>%
  mutate(
    won = ifelse(is.na(winner), "no", winner)
  ) %>%
  ungroup() %>%
  group_by(name) %>%
  mutate(
    won_previously = ifelse(lag(won != "no", default = FALSE), TRUE, FALSE)) %>%
  ungroup() %>%
  mutate(
    won_previously = ifelse(won_previously == TRUE, 1, 0)
  ) %>%
  group_by(name) %>%
  # Fill the 'nominated_previously' column down for each name
  mutate(won_previously = cummax(won_previously)) %>% 
  ungroup() %>%
  select(-won)

nominees <- actors %>%
  mutate(nominated_years = str_remove_all(nominated_years, "\\[|\\]")) %>%
  separate_rows(nominated_years, sep = ",\\s*") %>%             
  mutate(nominated_years = as.integer(nominated_years)) %>%
  select(name, nominated_years) %>%
  mutate(nominee = ifelse(!is.na(nominated_years), "yes", "no"))

nominees_filled <- nominees %>%
  # Create a data frame of all names and years
  distinct(name) %>%
  expand(name, nominated_years = years_seq) %>%
  left_join(nominees, by = c("name", "nominated_years")) %>%
  rename(year = nominated_years) %>%
  group_by(name) %>%
  mutate(
    nominated = ifelse(is.na(nominee), "no", nominee)  # Ensure no NAs in 'nominated' column
  ) %>%
  ungroup() %>%
  group_by(name) %>%
  mutate(
    nominated_previously = ifelse(lag(nominated == "yes", default = FALSE), TRUE, FALSE)
  ) %>%
  ungroup() %>%
  mutate(
    nominated_previously = as.integer(nominated_previously)
  ) %>%
  group_by(name) %>%
  # Fill the 'nominated_previously' column down for each name
  mutate(nominated_previously = cummax(nominated_previously)) %>% 
  ungroup() %>%
  select(-nominated)

winners_filled <- winners_filled %>%
  left_join(features, by = "name") %>%
  mutate(age = year - age)
prev_win <- winners_filled %>%
  select(name, year, won_previously)
nominees_filled <- nominees_filled %>%
  left_join(features, by = "name") %>%
  left_join(prev_win, by = c("name", "year")) %>%
  mutate(age = year - age)

trend_ts_data_all <- trends %>%
  mutate(year = year(Month),
         name = tolower(name)) %>%
  group_by(name, year) %>%
  arrange(Month) %>%
  summarise(
    ts_data = list(ts(value, frequency = 12)),
    var = var(value, na.rm = TRUE),
    .groups = "drop"
  )

zero_variance_log <- trend_ts_data_all %>%
  filter(is.na(var) | var == 0)

trend_ts_data <- trend_ts_data_all %>%
  filter(!is.na(var) & var > 0) %>%
  select(-var) %>%
  filter(year != 2025)

# feature extraction and custom max spike height
trend_features_ts <- trend_ts_data %>%
  mutate(
    features = map(ts_data, ~ tsfeatures(.x)), 
    max_spike_height = map_dbl(ts_data, ~ max(.x, na.rm = TRUE))
  ) %>%
  unnest(features)

# --- 4. Merge with Oscar outcomes ---
model_data <- trend_features_ts %>%
  left_join(nominees_filled, by = c("name", "year")) %>%
  mutate(
    nominee = factor(ifelse(is.na(nominee), 0, 1))
  ) %>%
  select(-frequency, -nperiods, -seasonal_period, -diff2_acf10, -seas_acf1)

#Train/test split
set.seed(90210)
data_split <- initial_split(model_data, prop = 0.8, strata = nominee)
train_data <- training(data_split)
test_data <- testing(data_split)

train_data <- train_data %>% select(-name, -ts_data, -year)
train_data_clean <- na.omit(train_data)

## undersampling
# Split the data into the two classes
non_nominee <- train_data_clean %>% filter(nominee == 0)
nominee <- train_data_clean %>% filter(nominee == 1)

# Randomly sample from the majority class (non-nominee) to match the minority class (nominee)
# Randomly sample the majority class (non-nominee) to match the minority class (nominee)

# Get the same proportion of non-nominee as nominee
if (nrow(non_nominee) >= nrow(nominee)) {
  non_nominee_undersampled <- non_nominee[sample(nrow(non_nominee), nrow(nominee)), ]
  
  # combine
  balanced_data <- bind_rows(non_nominee_undersampled, nominee)
  
  # shuffle 
  balanced_data <- balanced_data %>% sample_frac(1)
  
  # confirm
  table(balanced_data$nominee)
} else {
  stop("Not enough non-nominee rows to sample from.")
}


# combine the undersampled non-nominee with the full nominee class
balanced_data <- bind_rows(non_nominee_undersampled, nominee)

# check the new balance of classes
table(balanced_data$nominee)
balanced_data$cluster <- as.factor(balanced_data$cluster)
balanced_data$gender <- as.factor(balanced_data$gender)
balanced_data$american <- as.factor(balanced_data$american)
balanced_data$won_previously <- as.factor(balanced_data$won_previously)
balanced_data$nominated_previously <- as.factor(balanced_data$nominated_previously)

balanced_data_1 <- balanced_data
balanced_data_2 <- balanced_data %>% select(-age, -gender, -american, -nominated_previously, -won_previously)

set.seed(90210)

# modeling all predictors 
data_split <- initial_split(balanced_data, prop = 0.8, strata = nominee)
train_data <- training(data_split)
test_data <- testing(data_split)

rf_model <- randomForest(nominee ~ ., data = train_data)

# model summary
print(rf_model)

predictions <- predict(rf_model, newdata = test_data)

# confusion Matrix
conf_matrix <- table(Predicted = predictions, Actual = test_data$nominee)

print(conf_matrix)

# accuracy
accuracy <- sum(predictions == test_data$nominee) / nrow(test_data)
print(paste("Accuracy: ", accuracy))

conf_matrix_caret <- confusionMatrix(predictions, test_data$nominee)

# evaluation metrics
print(conf_matrix_caret)

importance(rf_model)
varImpPlot(rf_model)

# modeling just time series predictors
data_split <- initial_split(balanced_data_2, prop = 0.8, strata = nominee)
train_data <- training(data_split)
test_data <- testing(data_split)

rf_model <- randomForest(nominee ~ ., data = train_data)

# model summary
print(rf_model)

predictions <- predict(rf_model, newdata = test_data)

# confusion Matrix
conf_matrix <- table(Predicted = predictions, Actual = test_data$nominee)

print(conf_matrix)

# accuracy
accuracy <- sum(predictions == test_data$nominee) / nrow(test_data)
print(paste("Accuracy: ", accuracy))

conf_matrix_caret <- confusionMatrix(predictions, test_data$nominee)

# evaluation metrics
print(conf_matrix_caret)

importance(rf_model)
varImpPlot(rf_model)
```

