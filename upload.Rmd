---
title: ""
output: html_document
---

**Test our models by uploading your own data!**

To download your own data:

- Go to [Google Trends](https://trends.google.com/trends/explore?date=all&geo=US) and make sure you are searching the "United States" for all years of data
- Search any actor you want
- Download from the graph where it says interest over time, download as a csv
- The csv will go to your downloads, upload it to the [upload data here folder](https://github.com/jo-schroeder/adec7430-final/tree/main/data/upload_data_here) of the GitHub repository, make sure you commit the upload (ask Joanna for permission)
- Wait for the website to rebuild (should take around 5 minutes, there will be a green check on the latest commit message on GitHub) 
- Refresh this page and see the analysis with the new data point!

```{r setup, include=FALSE}
# loading packages
library(lubridate)
library(dtwclust)
library(ggthemes)
library(ggplot2)
library(plotly)
library(dplyr)
library(tidyr)
library(tsfeatures)
library(tidymodels)
library(purrr)
library(readr)
library(stringr)
library(caret)
library(randomForest)
library(tibble)

# load in data
data_dir <- "./data/"
actors <- read_csv(paste0(data_dir, "actors_features.csv"))
trends <- read_csv(paste0(data_dir, "trends.csv"))
existing_actors <- colnames(trends)

knitr::opts_chunk$set(
  message = FALSE, warning = FALSE, echo = FALSE
)

# check if any data has been uploaded
uploaded_data_dir <- paste0(data_dir, "upload_data_here/")
new_files <- list.files(uploaded_data_dir)

if (length(new_files) > 0) {
  # Read all files into a list of data frames
  data_list <- lapply(new_files, function(f) {
    read_csv(file.path(uploaded_data_dir, f), skip = 1)
  })

  if (length(data_list) == 1) {
    uploaded_data <- data_list[[1]]
  } else {

    uploaded_data <- Reduce(function(x, y) left_join(x, y, by = "Month"), data_list)
  }
  
  colnames(uploaded_data) <- gsub(": \\(United States\\)", "", colnames(uploaded_data))
  uploaded_data <- head(uploaded_data, 255)

}

```

```{r eval = !(exists("uploaded_data")), results = "asis"}
cat("Nothing has been uploaded.")
```

```{r eval = exists("uploaded_data"), results = "asis"}
trends <- left_join(trends, uploaded_data)
second_colname <- colnames(trends)[2]
last_colname <- tail(colnames(trends), 1)
uploaded_colnames <- colnames(uploaded_data)[-1]
```


```{r eval = exists("uploaded_data"), results = "asis"}
cat("You uploaded: ", uploaded_colnames, ".")

if (uploaded_colnames %in% existing_actors){
  cat("\n", uploaded_colnames, "is already in our dataset")
  uploaded_data <- NULL
} else if (!is.null(uploaded_data) && nrow(uploaded_data) < 255){
  cat("\nYou didn't upload the full time series since 2004")
  uploaded_data <- NULL
} else {
  cat("\nThe data looks good!")
}
```

```{r eval = exists("uploaded_data")}
# interactive trends plot
p <- plot_ly(type = "scatter", mode = "lines")

trends <- trends %>%
  mutate(across(everything(), ~ ifelse(. == "<1", 0, .))) %>%
  mutate(across(c(second_colname:last_colname), ~ as.numeric(.))) %>%
  pivot_longer(cols = c(second_colname:last_colname)) %>%
  mutate(Month = ym(Month),
         uploaded = ifelse(name %in% uploaded_colnames, TRUE, FALSE))

trends %>%
  group_by(name) %>%
  group_split() %>%
  purrr::walk(function(df) {
    p <<- add_trace(p,
                    data = df,
                    x = ~Month,
                    y = ~value,
                    name = unique(df$name),
                    text = ~paste(name, value),
                    hoverinfo = "text",
                    visible = "legendonly")
  })

p %>%
  layout(
    title = "Monthly Search Interest for Selected Actors since 2004",
    xaxis = list(title = "Month", range = c("2004-01-01",
                                            "2025-03-01")),
    yaxis = list(title = "Google Trend Search Interest", range = c(0, 100)),
    legend = list(title = list(text = "Select an Actor"))
  )


# joining 
joined <- trends %>% 
  mutate(name = tolower(name)) %>%
  left_join(actors, by = c("name")) 
```

```{r, eval = exists("uploaded_data"), results='asis'}
wide <- trends %>%
  pivot_wider(names_from = Month, values_from = value) %>%
  tibble::column_to_rownames("name")
ts_matrix <- as.matrix(wide)

clusters <- tsclust(ts_matrix,
                    type = "partitional",
                    k = 5,  # tune this
                    distance = "sbd",
                    centroid = "shape",  # required with SBD
                    control = partitional_control(iter.max = 50),
                    seed = 90210)

cluster_assignments <- clusters@cluster  # cluster labels for each series
distances <- clusters@cldist

# Create a data frame with rownames and cluster assignment
cluster_df <- data.frame(
  name = rownames(ts_matrix),
  cluster = cluster_assignments,
  distance = distances
)

actor_with_cluster <- left_join(trends, cluster_df, by = "name") %>%
  mutate(cluster_label = case_when(
    cluster == 1 ~ paste0(cluster, "- Blockbuster Staple"),
    cluster == 2 ~ paste0(cluster, "- Breakout Star or Memorialized"),
    cluster == 3 ~ paste0(cluster, "- Critically Acclaimed"),
    cluster == 4 ~ paste0(cluster, "- Pop Fame"),
    cluster == 5 ~ paste0(cluster, "- Emerging or Consistent Stardom")
  ))

uploaded_cluster <- actor_with_cluster %>% filter(name == uploaded_colnames) %>% distinct(cluster) %>% pull(cluster_label)

cat(uploaded_colnames, "would be in cluster", uploaded_cluster)
```


```{r eval = exists("uploaded_data"), include = FALSE}
years_seq <- 2004:2024

cluster_df <- cluster_df %>%
  distinct(name, cluster) %>%
  mutate(name = tolower(name))

features <- actors %>% 
  left_join(cluster_df, by = ("name")) %>% 
  select(name, age, gender, american, cluster)

winners <- actors %>%
  mutate(year_winner = str_remove_all(year_winner, "\\[|\\]")) %>%
  separate_rows(year_winner, sep = ",\\s*") %>%             
  mutate(year_winner = as.integer(year_winner)) %>%
  select(name, winner, year_winner)

# Cross join name and years_seq
winners_filled <- winners %>%
  # Create a data frame of all names and years
  distinct(name) %>%
  expand(name, year_winner = years_seq) %>%
  left_join(winners, by = c("name", "year_winner")) %>%
  rename(year = year_winner) %>%
  group_by(name) %>%
  mutate(
    won = ifelse(is.na(winner), "no", winner)
  ) %>%
  ungroup() %>%
  group_by(name) %>%
  mutate(
    won_previously = ifelse(lag(won != "no", default = FALSE), TRUE, FALSE)) %>%
  ungroup() %>%
  mutate(
    won_previously = ifelse(won_previously == TRUE, 1, 0)
  ) %>%
  group_by(name) %>%
  # Fill the 'nominated_previously' column down for each name
  mutate(won_previously = cummax(won_previously)) %>% 
  ungroup() %>%
  select(-won)

nominees <- actors %>%
  mutate(nominated_years = str_remove_all(nominated_years, "\\[|\\]")) %>%
  separate_rows(nominated_years, sep = ",\\s*") %>%             
  mutate(nominated_years = as.integer(nominated_years)) %>%
  select(name, nominated_years) %>%
  mutate(nominee = ifelse(!is.na(nominated_years), "yes", "no"))

nominees_filled <- nominees %>%
  # Create a data frame of all names and years
  distinct(name) %>%
  expand(name, nominated_years = years_seq) %>%
  left_join(nominees, by = c("name", "nominated_years")) %>%
  rename(year = nominated_years) %>%
  group_by(name) %>%
  mutate(
    nominated = ifelse(is.na(nominee), "no", nominee)  # Ensure no NAs in 'nominated' column
  ) %>%
  ungroup() %>%
  group_by(name) %>%
  mutate(
    nominated_previously = ifelse(lag(nominated == "yes", default = FALSE), TRUE, FALSE)
  ) %>%
  ungroup() %>%
  mutate(
    nominated_previously = as.integer(nominated_previously)
  ) %>%
  group_by(name) %>%
  # Fill the 'nominated_previously' column down for each name
  mutate(nominated_previously = cummax(nominated_previously)) %>% 
  ungroup() %>%
  select(-nominated)

winners_filled <- winners_filled %>%
  left_join(features, by = "name") %>%
  mutate(age = year - age)
prev_win <- winners_filled %>%
  select(name, year, won_previously)
nominees_filled <- nominees_filled %>%
  left_join(features, by = "name") %>%
  left_join(prev_win, by = c("name", "year")) %>%
  mutate(age = year - age)


trend_ts_data_all <- trends %>%
  mutate(year = year(Month),
         name = tolower(name)) %>%
  group_by(name, year) %>%
  arrange(Month) %>%
  summarise(
    ts_data = list(ts(value, frequency = 12)),
    var = var(value, na.rm = TRUE),
    .groups = "drop"
  )

trend_ts_data <- trend_ts_data_all %>%
  filter(!is.na(var) & var > 0) %>%
  select(-var) %>%
  filter(year != 2025)

# feature extraction + custom max spike height
trend_features_ts <- trend_ts_data %>%
  mutate(
    features = map(ts_data, ~ tsfeatures(.x)),  
    max_spike_height = map_dbl(ts_data, ~ max(.x, na.rm = TRUE))
  ) %>%
  unnest(features)

model_data <- trend_features_ts %>%
  left_join(nominees_filled, by = c("name", "year")) %>%
  mutate(
    nominee = factor(ifelse(is.na(nominee), 0, 1))  
  ) %>%
  select(-frequency, -nperiods, -seasonal_period, -diff2_acf10, -seas_acf1)
```

```{r eval = exists("uploaded_data"), include = FALSE}
set.seed(90210)
model_data2 <- model_data %>%
  mutate(across(c(cluster, gender, american, won_previously, nominated_previously), as.factor)) %>%
  drop_na() %>%
  mutate(row_id = row_number())
  
# Save for reconnecting later
id_lookup <- model_data2 %>% select(row_id, name, year)

# Drop unused columns and handle factors
model_data2 <- model_data2 %>% select(-name, -ts_data, -year, -row_id, -age, -gender, -american, -nominated_previously, -won_previously)

# Define a function to build a workflow with downsampling and cross-validation
define_modeling_workflow <- function(data) {
  # Split data
  data_split <- initial_split(data, prop = 0.8, strata = nominee)
  train_data <- training(data_split)
  test_data <- testing(data_split)

  # Cross-validation folds
  folds <- vfold_cv(train_data, v = 5, strata = nominee)

  # Recipe with downsampling
  rf_recipe <- recipe(nominee ~ ., data = train_data) %>%
    step_downsample(nominee)

  # Random forest model
  rf_model <- 
    rand_forest(mode = "classification") %>%
    set_engine("randomForest")

  # Workflow
  rf_workflow <- workflow() %>%
    add_model(rf_model) %>%
    add_recipe(rf_recipe)

  list(
    workflow = rf_workflow,
    folds = folds,
    test_data = test_data
  )
}

# Run for time series predictors only
workflow_ts <- define_modeling_workflow(model_data2)
rf_results_ts <- fit_resamples(
  workflow_ts$workflow,
  resamples = workflow_ts$folds,
  metrics = metric_set(accuracy, roc_auc),
  control = control_resamples(save_pred = TRUE)
)
final_preds_ts <- collect_predictions(rf_results_ts)

collect_metrics(rf_results_ts)

uploaded_preds <- final_preds_ts %>%
  left_join(id_lookup, by = c(".row" = "row_id")) %>%
  mutate(model_type = "TS Predictors Only") %>%
  filter(name == tolower(uploaded_colnames)) %>%
  select(year, .pred_class)

uploaded_preds %>%
  kable(col.names = c("Year", "Prediction")) %>%
  add_header_above(c(paste0("Predictions for ", uploaded_colnames) = 2)) %>%
  kable_styling(full_width = FALSE)
```